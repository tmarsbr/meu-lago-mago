{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79564685-afa6-4822-86ad-5c2540a696b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üì• Pipeline de Ingest√£o CDC - Upcell\n",
    "\n",
    "Este notebook implementa o pipeline de ingest√£o de dados CDC (Change Data Capture) do S3 para o Bronze no Databricks.\n",
    "\n",
    "## üéØ Objetivo\n",
    "- **Full-load**: Carga inicial completa das tabelas\n",
    "- **CDC**: Ingest√£o incremental com opera√ß√µes Insert, Update e Delete\n",
    "- **Delta Lake**: Merge at√¥mico na camada Bronze\n",
    "\n",
    "## üìã Requisitos\n",
    "- Tabelas no S3: `s3://meudatalake-raw/upcell/`\n",
    "- Cat√°logo: `bronze.upcell`\n",
    "- Coluna de controle: `DtAtualizacao` (presente em todos os arquivos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "daad10e8-bdba-4371-adc7-4876d7aa974d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0583b1c-da9b-4460-80d3-b4b4c44c0ec2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1Ô∏è‚É£ Importa√ß√µes e Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1bd9192-ac1b-47a7-b74c-0dbc9dd58142",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.catalog.clearCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "738eed4f-552c-406f-aaa4-8d7c273c049a",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"IdProduto\":253},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1759522837609}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Teste: Visualizar arquivos CDC dispon√≠veis\n",
    "df_test = spark.read.format(\"parquet\").load(f\"/Volumes/raw/upcell/cdc/transacoes/\")\n",
    "print(f\"Total de registros CDC: {df_test.count()}\")\n",
    "print(f\"Colunas: {df_test.columns}\")\n",
    "display(df_test.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e47c0ecf-3b66-4795-8540-b1ccb1cab09c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def table_exists(catalog, database, table):\n",
    "    count = (spark.sql(f\"SHOW TABLES IN `{catalog}`.`{database}`\")\n",
    "               .filter(f\"database = '{database}' AND tableName = '{table}'\")\n",
    "               .count())\n",
    "    return count == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ec0451d-f1c7-458e-b4c1-5a5c577dafe6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog = \"bronze\"\n",
    "schema = \"upcell\"\n",
    "tablename = \"transacoes\"\n",
    "id_field = \"IdTransacao\"\n",
    "timefield = \"DtAtualizacao\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab62865b-cc47-4624-8e4b-43b6a1e80c86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2Ô∏è‚É£ Configura√ß√£o da Tabela\n",
    "\n",
    "Defina a tabela que ser√° processada e os campos de controle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "695b4c24-a460-4a71-8355-5bd71401d147",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Carga inicial: Cria tabela Delta a partir do full-load\n",
    "if not table_exists(catalog, schema, tablename):\n",
    "    print(f\"‚ö†Ô∏è  Tabela {catalog}.{schema}.{tablename} N√ÉO existe. Criando a partir do full-load...\")\n",
    "\n",
    "    # L√™ full-load (j√° tem DtAtualizacao!)\n",
    "    df_full = spark.read.format(\"parquet\").load(f\"/Volumes/raw/upcell/full-load/{tablename}\")\n",
    "    \n",
    "    print(f\"üìä Total de registros no full-load: {df_full.count():,}\")\n",
    "\n",
    "    # Cria tabela Delta\n",
    "    (df_full.coalesce(1)\n",
    "            .write\n",
    "            .format(\"delta\")\n",
    "            .mode(\"overwrite\")\n",
    "            .saveAsTable(f\"{catalog}.{schema}.{tablename}\"))\n",
    "    \n",
    "    print(f\"‚úÖ Tabela {catalog}.{schema}.{tablename} criada com sucesso!\")\n",
    "    \n",
    "else:\n",
    "    print(f\"‚úÖ Tabela {catalog}.{schema}.{tablename} j√° existe. Pular para o CDC merge.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10aedc79-23dd-444e-be0e-1ecb322f9c34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3Ô∏è‚É£ Full-Load (Carga Inicial)\n",
    "\n",
    "Se a tabela n√£o existe, cria a partir dos dados de full-load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98bf0438-167c-4336-9de0-7636723e3a7e",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1759523012519}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Processa CDC: Deduplica e pega apenas o registro mais recente por chave\n",
    "print(\"üì• Carregando dados CDC...\")\n",
    "\n",
    "(spark.read\n",
    "    .format(\"parquet\")\n",
    "    .load(f\"/Volumes/raw/upcell/cdc/{tablename}\")\n",
    "    .createOrReplaceTempView(f\"view_{tablename}\"))\n",
    "\n",
    "# Query para pegar apenas o √∫ltimo registro de cada chave\n",
    "query = f\"\"\"\n",
    "    SELECT *  \n",
    "    FROM view_{tablename}\n",
    "    QUALIFY ROW_NUMBER() OVER(PARTITION BY {id_field} ORDER BY {timefield} DESC) = 1\n",
    "\"\"\"\n",
    "\n",
    "df_cdc_unique = spark.sql(query)\n",
    "\n",
    "print(f\"üìä Total de registros CDC √∫nicos: {df_cdc_unique.count():,}\")\n",
    "print(f\"üìã Opera√ß√µes no CDC:\")\n",
    "df_cdc_unique.groupBy(\"op\").count().display()\n",
    "\n",
    "print(\"\\nüîç Sample de registros CDC:\")\n",
    "df_cdc_unique.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17bf0a7d-e81e-4a28-a4c8-51a624a441d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4Ô∏è‚É£ Processamento CDC\n",
    "\n",
    "Carrega arquivos CDC, deduplica e prepara para o merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "993dd37d-2020-4199-9953-755f19cc570c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bronze = delta.DeltaTable.forName(spark, f\"{catalog}.{schema}.{tablename}\")\n",
    "bronze\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc23dfc8-bef3-4816-b7b0-e514a3a3cc3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# üìä ANTES DO MERGE: Captura estat√≠sticas atuais\n",
    "print(\"=\" * 60)\n",
    "print(\"üìä ESTAT√çSTICAS ANTES DO MERGE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Contagem total antes\n",
    "count_before = spark.sql(f\"SELECT COUNT(*) as total FROM {catalog}.{schema}.{tablename}\").collect()[0]['total']\n",
    "print(f\"\\n‚úÖ Total de registros ANTES: {count_before:,}\")\n",
    "\n",
    "# Detalhes da tabela antes\n",
    "details_before = spark.sql(f\"DESCRIBE DETAIL {catalog}.{schema}.{tablename}\").select(\"numFiles\", \"sizeInBytes\").collect()[0]\n",
    "print(f\"üìÅ Arquivos: {details_before['numFiles']}\")\n",
    "print(f\"üíæ Tamanho: {details_before['sizeInBytes']:,} bytes ({details_before['sizeInBytes'] / (1024*1024):.2f} MB)\")\n",
    "\n",
    "# √öltima atualiza√ß√£o antes\n",
    "last_update_before = spark.sql(f\"\"\"\n",
    "    SELECT MAX(DtAtualizacao) as ultima_atualizacao \n",
    "    FROM {catalog}.{schema}.{tablename}\n",
    "\"\"\").collect()[0]['ultima_atualizacao']\n",
    "print(f\"üïê √öltima atualiza√ß√£o: {last_update_before}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14128293-5e45-44b0-aab8-297b23d494f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Merge CDC na tabela Delta Bronze\n",
    "print(\"üîÑ Executando merge CDC na tabela Bronze...\")\n",
    "\n",
    "bronze = delta.DeltaTable.forName(spark, f\"{catalog}.{schema}.{tablename}\")\n",
    "\n",
    "(bronze.alias(\"b\") \n",
    "  .merge(df_cdc_unique.alias(\"d\"), f\"b.{id_field} = d.{id_field}\") \n",
    "  .whenMatchedDelete(condition = \"d.op = 'D'\")           # Delete se op = 'D'\n",
    "  .whenMatchedUpdateAll(condition = \"d.op = 'U'\")        # Update se op = 'U'\n",
    "  .whenNotMatchedInsertAll(condition = \"d.op = 'I'\")     # Insert se op = 'I'\n",
    "  .execute()\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Merge CDC executado com sucesso!\")\n",
    "\n",
    "# üìä DEPOIS DO MERGE: Captura estat√≠sticas atualizadas\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä ESTAT√çSTICAS DEPOIS DO MERGE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Contagem total depois\n",
    "count_after = spark.sql(f\"SELECT COUNT(*) as total FROM {catalog}.{schema}.{tablename}\").collect()[0]['total']\n",
    "print(f\"\\n‚úÖ Total de registros DEPOIS: {count_after:,}\")\n",
    "\n",
    "# Detalhes da tabela depois\n",
    "details_after = spark.sql(f\"DESCRIBE DETAIL {catalog}.{schema}.{tablename}\").select(\"numFiles\", \"sizeInBytes\").collect()[0]\n",
    "print(f\"üìÅ Arquivos: {details_after['numFiles']}\")\n",
    "print(f\"üíæ Tamanho: {details_after['sizeInBytes']:,} bytes ({details_after['sizeInBytes'] / (1024*1024):.2f} MB)\")\n",
    "\n",
    "# √öltima atualiza√ß√£o depois\n",
    "last_update_after = spark.sql(f\"\"\"\n",
    "    SELECT MAX(DtAtualizacao) as ultima_atualizacao \n",
    "    FROM {catalog}.{schema}.{tablename}\n",
    "\"\"\").collect()[0]['ultima_atualizacao']\n",
    "print(f\"üïê √öltima atualiza√ß√£o: {last_update_after}\")\n",
    "\n",
    "# üîÑ COMPARA√á√ÉO: Calcula diferen√ßas\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üîÑ COMPARA√á√ÉO: ANTES vs DEPOIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "diff_records = count_after - count_before\n",
    "diff_size = details_after['sizeInBytes'] - details_before['sizeInBytes']\n",
    "diff_files = details_after['numFiles'] - details_before['numFiles']\n",
    "\n",
    "print(f\"\\nüìä Diferen√ßa de registros: {diff_records:+,} ({'+' if diff_records >= 0 else ''}{(diff_records/count_before*100):.2f}%)\")\n",
    "print(f\"üíæ Diferen√ßa de tamanho: {diff_size:+,} bytes ({diff_size / (1024*1024):+.2f} MB)\")\n",
    "print(f\"üìÅ Diferen√ßa de arquivos: {diff_files:+}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe2ce052-e9dd-43ff-8617-d1af155ccd7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5Ô∏è‚É£ Merge CDC na Tabela Delta\n",
    "\n",
    "Aplica as opera√ß√µes de Insert, Update e Delete na camada Bronze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec6457a3-0ca6-4cff-b085-4881b936c9d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Valida√ß√£o 1: Contagem total de registros\n",
    "total = spark.sql(f\"SELECT COUNT(*) as total FROM {catalog}.{schema}.{tablename}\").collect()[0]['total']\n",
    "print(f\"üìä Total de registros na tabela Bronze: {total:,}\")\n",
    "\n",
    "# Valida√ß√£o 2: Verificar se DtAtualizacao est√° presente\n",
    "sample = spark.sql(f\"SELECT * FROM {catalog}.{schema}.{tablename} LIMIT 5\")\n",
    "print(f\"\\n‚úÖ Colunas da tabela: {sample.columns}\")\n",
    "sample.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86cb79af-c533-4e72-bf90-36f55ce16371",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Valida√ß√£o 3: Verificar hist√≥rico de vers√µes Delta\n",
    "print(\"üìú Hist√≥rico de vers√µes da tabela Delta:\\n\")\n",
    "spark.sql(f\"DESCRIBE HISTORY {catalog}.{schema}.{tablename}\").select(\n",
    "    \"version\", \n",
    "    \"timestamp\", \n",
    "    \"operation\", \n",
    "    \"operationMetrics\"\n",
    ").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "577ecea5-c1db-4675-80a6-00a41f45b375",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "display(\n",
    "    spark.sql(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "            DATE(DtAtualizacao) as data_atualizacao,\n",
    "            COUNT(*) as total_registros,\n",
    "            MIN(DtAtualizacao) as primeira_atualizacao,\n",
    "            MAX(DtAtualizacao) as ultima_atualizacao\n",
    "        FROM bronze.upcell.transacao_produto\n",
    "        GROUP BY DATE(DtAtualizacao)\n",
    "        ORDER BY data_atualizacao DESC\n",
    "        \"\"\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57499518-ee1b-4d7e-a2fa-aa75f3f35c7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### üéØ Pr√≥ximos Passos:\n",
    "\n",
    "1. **Executar para outras tabelas**: Altere a vari√°vel `tablename` para processar:\n",
    "   - `clientes`\n",
    "   - `produtos`\n",
    "   - `transacoes`\n",
    "\n",
    "2. **Agendar execu√ß√£o**: Configure um Job no Databricks para rodar periodicamente\n",
    "\n",
    "3. **Otimizar tabela**: Execute `OPTIMIZE` e `VACUUM` periodicamente:\n",
    "   ```sql\n",
    "   OPTIMIZE bronze.upcell.transacao_produto;\n",
    "   VACUUM bronze.upcell.transacao_produto RETAIN 168 HOURS;\n",
    "   ```\n",
    "\n",
    "4. **Monitorar**: Use `DESCRIBE HISTORY` para acompanhar vers√µes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0acd8a4-2272-438f-9fc8-fc60719a69e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 6Ô∏è‚É£ Valida√ß√£o Final\n",
    "\n",
    "Consulta a tabela Bronze para validar os dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b4226c7-ecd7-4018-8698-b0ca67c3cebd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## üìö Refer√™ncia: Opera√ß√µes CDC\n",
    "\n",
    "| Opera√ß√£o | C√≥digo | Descri√ß√£o | A√ß√£o no Merge |\n",
    "|----------|--------|-----------|---------------|\n",
    "| **Insert** | `I` | Novo registro | `whenNotMatchedInsertAll()` |\n",
    "| **Update** | `U` | Registro atualizado | `whenMatchedUpdateAll()` |\n",
    "| **Delete** | `D` | Registro deletado | `whenMatchedDelete()` |\n",
    "\n",
    "### üîç Como Funciona o QUALIFY:\n",
    "\n",
    "```sql\n",
    "QUALIFY ROW_NUMBER() OVER(PARTITION BY {id_field} ORDER BY {timefield} DESC) = 1\n",
    "```\n",
    "\n",
    "- **PARTITION BY**: Agrupa por chave prim√°ria\n",
    "- **ORDER BY DESC**: Ordena pelo timestamp (mais recente primeiro)\n",
    "- **ROW_NUMBER() = 1**: Pega apenas o registro mais recente de cada chave\n",
    "\n",
    "### ‚úÖ Checklist de Valida√ß√£o:\n",
    "\n",
    "- [ ] Full-load executado com sucesso\n",
    "- [ ] CDC processado sem erros\n",
    "- [ ] Merge aplicado corretamente\n",
    "- [ ] Contagem de registros confere\n",
    "- [ ] Coluna `DtAtualizacao` presente em todos os registros"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5062531956061245,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "ingestao",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
